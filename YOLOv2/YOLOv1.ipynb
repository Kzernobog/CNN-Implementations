{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLOv1 Implementation\n",
    "\n",
    "This notebook aims to implement the YOLOv2 object detection algorithm and replicate the results as given in [this](https://pjreddie.com/media/files/papers/yolo_1.pdf) paper.\n",
    "\n",
    "Steps involved:\n",
    "- Pre-training weights on ImageNet dataset.\n",
    "- implement the YOLOv1 model\n",
    "\n",
    "\n",
    "### Step 1\n",
    "Pre-training weights on ImageNet dataset\n",
    "- prepare the modified network model\n",
    "- prepare the dataset for training - ImageNet dataset\n",
    "- Implement debugging functions for training\n",
    "- train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib as plt\n",
    "import xml.etree.ElementTree as ET\n",
    "from yolo_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_placeholders(n_H, n_W, n_C, n_y):\n",
    "    '''\n",
    "    Function to create placeholder for tensorflow session\n",
    "    \n",
    "    Args:\n",
    "    n_H = height of the image\n",
    "    n_W = width of image\n",
    "    n_C = number of channels\n",
    "    n_y = number of output features\n",
    "    \n",
    "    returns:\n",
    "    X,Y\n",
    "    '''\n",
    "    X = tf.placeholder(tf.float32, shape = (None, n_H, n_W, n_C))\n",
    "    Y = tf.placeholder(tf.float32, shape = (None, n_y))\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_train_parameters = initialize_weights(YOLOv1_Pre_trained_Model.xml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation_pretrain(X, pre_train_parameters):\n",
    "    '''\n",
    "    Args:\n",
    "    X - placeholder for the initial feature tensor\n",
    "    pre_train_parameters - dictionary containing filters\n",
    "    \n",
    "    returns\n",
    "    Z8 - output of the last LINEAR layer\n",
    "    \n",
    "    NOT IMPLEMENTED: NORMALIZATION\n",
    "    '''\n",
    "    \n",
    "    Z1 = tf.nn.conv2d(X, pre_train_parameters['W01'], [1,2,2,1], padding=\"VALID\")\n",
    "    Z1 = tf.nn.bias_add(Z1, pre_train_parameters['B01'])\n",
    "    A1 = tf.nn.leaky_relu(Z1, alpha=0.1)\n",
    "    P1 = tf.nn.max_pool(A1, [1,2,2,1], [1,2,2,1], padding=\"VALID\")\n",
    "    \n",
    "    \n",
    "    Z2 = tf.nn.conv2d(P1, pre_train_parameters['W02'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z2 = tf.nn.bias_add(Z2, pre_train_parameters['B02'])\n",
    "    A2 = tf.nn.leaky_relu(Z2, alpha=0.1)\n",
    "    P2 = tf.nn.max_pool(A2, [1,2,2,1], [1,2,2,1], padding=\"VALID\")\n",
    "    \n",
    "    Z3 = tf.nn.conv2d(P2, pre_train_parameters['W03'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z3 = tf.nn.bias_add(Z3, pre_train_parameters['B03'])\n",
    "    A3 = tf.nn.leaky_relu(Z3, alpha=0.1)\n",
    "    Z4 = tf.nn.conv2d(A3, pre_train_parameters['W04'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z4 = tf.nn.bias_add(Z4, pre_train_parameters['B04'])\n",
    "    A4 = tf.nn.leaky_relu(Z4, alpha=0.1)\n",
    "    Z5 = tf.nn.conv2d(A4, pre_train_parameters['W05'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z5 = tf.nn.bias_add(Z5, pre_train_parameters['B05'])\n",
    "    A5 = tf.nn.leaky_relu(Z5, alpha=0.1)\n",
    "    Z6 = tf.nn.conv2d(A5, pre_train_parameters['W06'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z6 = tf.nn.bias_add(Z6, pre_train_parameters['B06'])\n",
    "    A6 = tf.nn.leaky_relu(Z6, alpha=0.1)\n",
    "    P3 = tf.nn.max_pool(A6, [1,2,2,1], [1,2,2,1], padding=\"VALID\")\n",
    "    \n",
    "    Z7 = tf.nn.conv2d(P3, pre_train_parameters['W07'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z7 = tf.nn.bias_add(Z7, pre_train_parameters['B07'])\n",
    "    A7 = tf.nn.leaky_relu(Z7, alpha=0.1)\n",
    "    Z8 = tf.nn.conv2d(A7, pre_train_parameters['W08'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z8 = tf.nn.bias_add(Z8, pre_train_parameters['B08'])\n",
    "    A8 = tf.nn.leaky_relu(Z8, alpha=0.1)\n",
    "    Z9 = tf.nn.conv2d(A8, pre_train_parameters['W09'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z9 = tf.nn.bias_add(Z9, pre_train_parameters['B09'])\n",
    "    A9 = tf.nn.leaky_relu(Z9, alpha=0.1)\n",
    "    Z10 = tf.nn.conv2d(A9, pre_train_parameters['W10'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z10 = tf.nn.bias_add(Z10, pre_train_parameters['B10'])\n",
    "    A10 = tf.nn.leaky_relu(Z10, alpha=0.1)\n",
    "    Z11 = tf.nn.conv2d(P10, pre_train_parameters['W11'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z11 = tf.nn.bias_add(Z11, pre_train_parameters['B11'])\n",
    "    A11 = tf.nn.leaky_relu(Z11, alpha=0.1)\n",
    "    Z12 = tf.nn.conv2d(A11, pre_train_parameters['W12'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z12 = tf.nn.bias_add(Z12, pre_train_parameters['B12'])\n",
    "    A12 = tf.nn.leaky_relu(Z12, alpha=0.1)\n",
    "    Z13 = tf.nn.conv2d(A12, pre_train_parameters['W13'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z13 = tf.nn.bias_add(Z13, pre_train_parameters['B13'])\n",
    "    A13 = tf.nn.leaky_relu(Z13, alpha=0.1)\n",
    "    Z14 = tf.nn.conv2d(A13, pre_train_parameters['W14'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z14 = tf.nn.bias_add(Z14, pre_train_parameters['B14'])\n",
    "    A14 = tf.nn.leaky_relu(Z14, alpha=0.1)\n",
    "    Z15 = tf.nn.conv2d(P4, pre_train_parameters['W15'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z15 = tf.nn.bias_add(Z15, pre_train_parameters['B15'])\n",
    "    A15 = tf.nn.leaky_relu(Z15, alpha=0.1)\n",
    "    Z16 = tf.nn.conv2d(A15, pre_train_parameters['W16'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z16 = tf.nn.bias_add(Z16, pre_train_parameters['B16'])\n",
    "    A16 = tf.nn.leaky_relu(Z16, alpha=0.1)\n",
    "    P4 = tf.nn.max_pool(A16, [1,2,2,1], [1,2,2,1], padding=\"VALID\")\n",
    "    \n",
    "    \n",
    "    Z17 = tf.nn.conv2d(P4, pre_train_parameters['W17'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z17 = tf.nn.bias_add(Z17, pre_train_parameters['B17'])\n",
    "    A17 = tf.nn.leaky_relu(Z17, alpha=0.1)\n",
    "    Z18 = tf.nn.conv2d(A17, pre_train_parameters['W18'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z18 = tf.nn.bias_add(Z18, pre_train_parameters['B18'])\n",
    "    A18 = tf.nn.leaky_relu(Z18, alpha=0.1)\n",
    "    Z19 = tf.nn.conv2d(A18, pre_train_parameters['W19'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z19 = tf.nn.bias_add(Z19, pre_train_parameters['B19'])\n",
    "    A19 = tf.nn.leaky_relu(Z19, alpha=0.1)\n",
    "    Z20 = tf.nn.conv2d(A19, pre_train_parameters['W20'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z20 = tf.nn.bias_add(Z20, pre_train_parameters['B20'])\n",
    "    \n",
    "    return Z20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2\n",
    "Implement the YOLOv1 model\n",
    "\n",
    "- Implement Forward Propagation function\n",
    "- Implement cost function\n",
    "- Implement model function\n",
    "\n",
    "Create placeholders for the feature and label tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = Tensor(\"Placeholder:0\", shape=(?, 448, 448, 3), dtype=float32)\n",
      "Y = Tensor(\"Placeholder_1:0\", shape=(?, 1000), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# test script for the create-placeholder function\n",
    "X, Y = create_placeholders(448, 448, 3, 1000)\n",
    "print (\"X = \" + str(X))\n",
    "print (\"Y = \" + str(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare and initialize the parameters that are used in the model. Traditional implementation of a CNN would have had to initialize them randomly. But the YOLOv1 model is pre-trained on ImageNet. These weights can be procured from Step 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "    \"\"\"\n",
    "    Yet to be coded\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the YOLOv1 CNN forward propogation function. Facts that you need to paid attention\n",
    "- Linear activation for the final layer, leaky relu for the rest with alpha = 0.1\n",
    "- Any image is resized to 448x448. This is the standard input.\n",
    "- Implement a function to load filter dimensions from an xml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 7, 3, 64]\n",
      "[3, 3, 64, 192]\n",
      "[1, 1, 192, 128]\n",
      "[3, 3, 128, 256]\n",
      "[1, 1, 256, 256]\n",
      "[3, 3, 256, 512]\n",
      "[1, 1, 512, 256]\n",
      "[3, 3, 256, 512]\n",
      "[1, 1, 512, 256]\n",
      "[3, 3, 256, 512]\n",
      "[1, 1, 512, 256]\n",
      "[3, 3, 256, 512]\n",
      "[1, 1, 512, 256]\n",
      "[3, 3, 256, 512]\n",
      "[1, 1, 512, 512]\n",
      "[3, 3, 512, 1024]\n",
      "[1, 1, 1024, 512]\n",
      "[3, 3, 512, 1024]\n",
      "[1, 1, 1024, 512]\n",
      "[3, 3, 512, 1024]\n",
      "[3, 3, 1024, 1024]\n",
      "[3, 3, 1024, 1024]\n",
      "[3, 3, 1024, 1024]\n",
      "[3, 3, 1024, 1024]\n",
      "{'W01': <tf.Variable 'W01:0' shape=(7, 7, 3, 64) dtype=float32_ref>, 'B01': <tf.Variable 'Variable:0' shape=(64,) dtype=float32_ref>, 'W02': <tf.Variable 'W02:0' shape=(3, 3, 64, 192) dtype=float32_ref>, 'B02': <tf.Variable 'Variable_1:0' shape=(192,) dtype=float32_ref>, 'W03': <tf.Variable 'W03:0' shape=(1, 1, 192, 128) dtype=float32_ref>, 'B03': <tf.Variable 'Variable_2:0' shape=(128,) dtype=float32_ref>, 'W04': <tf.Variable 'W04:0' shape=(3, 3, 128, 256) dtype=float32_ref>, 'B04': <tf.Variable 'Variable_3:0' shape=(256,) dtype=float32_ref>, 'W05': <tf.Variable 'W05:0' shape=(1, 1, 256, 256) dtype=float32_ref>, 'B05': <tf.Variable 'Variable_4:0' shape=(256,) dtype=float32_ref>, 'W06': <tf.Variable 'W06:0' shape=(3, 3, 256, 512) dtype=float32_ref>, 'B06': <tf.Variable 'Variable_5:0' shape=(512,) dtype=float32_ref>, 'W07': <tf.Variable 'W07:0' shape=(1, 1, 512, 256) dtype=float32_ref>, 'B07': <tf.Variable 'Variable_6:0' shape=(256,) dtype=float32_ref>, 'W08': <tf.Variable 'W08:0' shape=(3, 3, 256, 512) dtype=float32_ref>, 'B08': <tf.Variable 'Variable_7:0' shape=(512,) dtype=float32_ref>, 'W09': <tf.Variable 'W09:0' shape=(1, 1, 512, 256) dtype=float32_ref>, 'B09': <tf.Variable 'Variable_8:0' shape=(256,) dtype=float32_ref>, 'W10': <tf.Variable 'W10:0' shape=(3, 3, 256, 512) dtype=float32_ref>, 'B10': <tf.Variable 'Variable_9:0' shape=(512,) dtype=float32_ref>, 'W11': <tf.Variable 'W11:0' shape=(1, 1, 512, 256) dtype=float32_ref>, 'B11': <tf.Variable 'Variable_10:0' shape=(256,) dtype=float32_ref>, 'W12': <tf.Variable 'W12:0' shape=(3, 3, 256, 512) dtype=float32_ref>, 'B12': <tf.Variable 'Variable_11:0' shape=(512,) dtype=float32_ref>, 'W13': <tf.Variable 'W13:0' shape=(1, 1, 512, 256) dtype=float32_ref>, 'B13': <tf.Variable 'Variable_12:0' shape=(256,) dtype=float32_ref>, 'W14': <tf.Variable 'W14:0' shape=(3, 3, 256, 512) dtype=float32_ref>, 'B14': <tf.Variable 'Variable_13:0' shape=(512,) dtype=float32_ref>, 'W15': <tf.Variable 'W15:0' shape=(1, 1, 512, 512) dtype=float32_ref>, 'B15': <tf.Variable 'Variable_14:0' shape=(512,) dtype=float32_ref>, 'W16': <tf.Variable 'W16:0' shape=(3, 3, 512, 1024) dtype=float32_ref>, 'B16': <tf.Variable 'Variable_15:0' shape=(1024,) dtype=float32_ref>, 'W17': <tf.Variable 'W17:0' shape=(1, 1, 1024, 512) dtype=float32_ref>, 'B17': <tf.Variable 'Variable_16:0' shape=(512,) dtype=float32_ref>, 'W18': <tf.Variable 'W18:0' shape=(3, 3, 512, 1024) dtype=float32_ref>, 'B18': <tf.Variable 'Variable_17:0' shape=(1024,) dtype=float32_ref>, 'W19': <tf.Variable 'W19:0' shape=(1, 1, 1024, 512) dtype=float32_ref>, 'B19': <tf.Variable 'Variable_18:0' shape=(512,) dtype=float32_ref>, 'W20': <tf.Variable 'W20:0' shape=(3, 3, 512, 1024) dtype=float32_ref>, 'B20': <tf.Variable 'Variable_19:0' shape=(1024,) dtype=float32_ref>, 'W21': <tf.Variable 'W21:0' shape=(3, 3, 1024, 1024) dtype=float32_ref>, 'B21': <tf.Variable 'Variable_20:0' shape=(1024,) dtype=float32_ref>, 'W22': <tf.Variable 'W22:0' shape=(3, 3, 1024, 1024) dtype=float32_ref>, 'B22': <tf.Variable 'Variable_21:0' shape=(1024,) dtype=float32_ref>, 'W23': <tf.Variable 'W23:0' shape=(3, 3, 1024, 1024) dtype=float32_ref>, 'B23': <tf.Variable 'Variable_22:0' shape=(1024,) dtype=float32_ref>, 'W24': <tf.Variable 'W24:0' shape=(3, 3, 1024, 1024) dtype=float32_ref>, 'B24': <tf.Variable 'Variable_23:0' shape=(1024,) dtype=float32_ref>}\n"
     ]
    }
   ],
   "source": [
    "# experimenting with the ElementTree API\n",
    "tf.reset_default_graph()\n",
    "parameters = {}\n",
    "tree = ET.parse('Configuration.xml')\n",
    "root = tree.getroot()\n",
    "for child in root:\n",
    "    size = []\n",
    "    for child1 in child:\n",
    "        # print(child.attrib['name'], child1.tag, child1.text)\n",
    "        if (child1.tag == 'dimension'):\n",
    "            size.append((int)(child1.text))\n",
    "            size.append((int)(child1.text))\n",
    "        if (child1.tag == 'input'):\n",
    "            size.append((int)(child1.text))\n",
    "        if (child1.tag == 'output'):\n",
    "            size.append((int)(child1.text))\n",
    "    print(size)\n",
    "    W = tf.get_variable(child.attrib['name'], size, initializer = tf.contrib.layers.xavier_initializer(seed = 0)) \n",
    "    parameters[child.attrib['name']] = W\n",
    "    B = tf.Variable(tf.constant(0.01, shape=[size[-1]]))\n",
    "    parameters['B'+(child.attrib['name'][1:])] = B\n",
    "print(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in parameters:\n",
    "    print(key, parameters[key])\n",
    "    print(parameters[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_initialize_weights(xml_file):\n",
    "    '''\n",
    "    Reads model parameter weights from xml_file and initializes filters and biases\n",
    "    \n",
    "    Args:\n",
    "    xml_file - configuration xml with absolute path\n",
    "    \n",
    "    Returns:\n",
    "    parameters - a dictionary containing initialized parameters\n",
    "    '''\n",
    "    parameters = {}\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    for child in root:\n",
    "        size = []\n",
    "        for child1 in child:\n",
    "            # print(child.attrib['name'], child1.tag, child1.text)\n",
    "            if (child1.tag == 'dimension'):\n",
    "                size.append((int)(child1.text))\n",
    "                size.append((int)(child1.text))\n",
    "            if (child1.tag == 'input'):\n",
    "                size.append((int)(child1.text))\n",
    "            if (child1.tag == 'output'):\n",
    "                size.append((int)(child1.text))\n",
    "        print(size)\n",
    "        W = tf.get_variable(child.attrib['name'], size, initializer = tf.contrib.layers.xavier_initializer(seed = 0)) \n",
    "        parameters[child.attrib['name']] = W\n",
    "        B = tf.Variable(tf.constant(0.01, shape=[size[-1]]))\n",
    "        parameters['B'+(child.attrib['name'][1:])] = B\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward Propogation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation_YOLOv1(X, parameters):\n",
    "    '''\n",
    "    Args:\n",
    "    X - placeholder for the initial feature tensor\n",
    "    parameters - dictionary containing filters\n",
    "    \n",
    "    returns\n",
    "    Z8 - output of the last LINEAR layer\n",
    "    \n",
    "    NOT IMPLEMENTED: NORMALIZATION\n",
    "    '''\n",
    "    \n",
    "    Z1 = tf.nn.conv2d(X, parameters['W01'], [1,2,2,1], padding=\"VALID\")\n",
    "    Z1 = tf.nn.bias_add(Z1, parameters['B01'])\n",
    "    A1 = tf.nn.leaky_relu(Z1, alpha=0.1)\n",
    "    P1 = tf.nn.max_pool(A1, [1,2,2,1], [1,2,2,1], padding=\"VALID\")\n",
    "    \n",
    "    \n",
    "    Z2 = tf.nn.conv2d(P1, parameters['W02'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z2 = tf.nn.bias_add(Z2, parameters['B02'])\n",
    "    A2 = tf.nn.leaky_relu(Z2, alpha=0.1)\n",
    "    P2 = tf.nn.max_pool(A2, [1,2,2,1], [1,2,2,1], padding=\"VALID\")\n",
    "    \n",
    "    Z3 = tf.nn.conv2d(P2, parameters['W03'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z3 = tf.nn.bias_add(Z3, parameters['B03'])\n",
    "    A3 = tf.nn.leaky_relu(Z3, alpha=0.1)\n",
    "    Z4 = tf.nn.conv2d(A3, parameters['W04'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z4 = tf.nn.bias_add(Z4, parameters['B04'])\n",
    "    A4 = tf.nn.leaky_relu(Z4, alpha=0.1)\n",
    "    Z5 = tf.nn.conv2d(A4, parameters['W05'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z5 = tf.nn.bias_add(Z5, parameters['B05'])\n",
    "    A5 = tf.nn.leaky_relu(Z5, alpha=0.1)\n",
    "    Z6 = tf.nn.conv2d(A5, parameters['W06'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z6 = tf.nn.bias_add(Z6, parameters['B06'])\n",
    "    A6 = tf.nn.leaky_relu(Z6, alpha=0.1)\n",
    "    P3 = tf.nn.max_pool(A6, [1,2,2,1], [1,2,2,1], padding=\"VALID\")\n",
    "    \n",
    "    Z7 = tf.nn.conv2d(P3, parameters['W07'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z7 = tf.nn.bias_add(Z7, parameters['B07'])\n",
    "    A7 = tf.nn.leaky_relu(Z7, alpha=0.1)\n",
    "    Z8 = tf.nn.conv2d(A7, parameters['W08'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z8 = tf.nn.bias_add(Z8, parameters['B08'])\n",
    "    A8 = tf.nn.leaky_relu(Z8, alpha=0.1)\n",
    "    Z9 = tf.nn.conv2d(A8, parameters['W09'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z9 = tf.nn.bias_add(Z9, parameters['B09'])\n",
    "    A9 = tf.nn.leaky_relu(Z9, alpha=0.1)\n",
    "    Z10 = tf.nn.conv2d(A9, parameters['W10'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z10 = tf.nn.bias_add(Z10, parameters['B10'])\n",
    "    A10 = tf.nn.leaky_relu(Z10, alpha=0.1)\n",
    "    Z11 = tf.nn.conv2d(P10, parameters['W11'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z11 = tf.nn.bias_add(Z11, parameters['B11'])\n",
    "    A11 = tf.nn.leaky_relu(Z11, alpha=0.1)\n",
    "    Z12 = tf.nn.conv2d(A11, parameters['W12'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z12 = tf.nn.bias_add(Z12, parameters['B12'])\n",
    "    A12 = tf.nn.leaky_relu(Z12, alpha=0.1)\n",
    "    Z13 = tf.nn.conv2d(A12, parameters['W13'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z13 = tf.nn.bias_add(Z13, parameters['B13'])\n",
    "    A13 = tf.nn.leaky_relu(Z13, alpha=0.1)\n",
    "    Z14 = tf.nn.conv2d(A13, parameters['W14'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z14 = tf.nn.bias_add(Z14, parameters['B14'])\n",
    "    A14 = tf.nn.leaky_relu(Z14, alpha=0.1)\n",
    "    Z15 = tf.nn.conv2d(P4, parameters['W15'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z15 = tf.nn.bias_add(Z15, parameters['B15'])\n",
    "    A15 = tf.nn.leaky_relu(Z15, alpha=0.1)\n",
    "    Z16 = tf.nn.conv2d(A15, parameters['W16'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z16 = tf.nn.bias_add(Z16, parameters['B16'])\n",
    "    A16 = tf.nn.leaky_relu(Z16, alpha=0.1)\n",
    "    P4 = tf.nn.max_pool(A16, [1,2,2,1], [1,2,2,1], padding=\"VALID\")\n",
    "    \n",
    "    \n",
    "    Z17 = tf.nn.conv2d(P4, parameters['W17'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z17 = tf.nn.bias_add(Z17, parameters['B17'])\n",
    "    A17 = tf.nn.leaky_relu(Z17, alpha=0.1)\n",
    "    Z18 = tf.nn.conv2d(A17, parameters['W18'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z18 = tf.nn.bias_add(Z18, parameters['B18'])\n",
    "    A18 = tf.nn.leaky_relu(Z18, alpha=0.1)\n",
    "    Z19 = tf.nn.conv2d(A18, parameters['W19'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z19 = tf.nn.bias_add(Z19, parameters['B19'])\n",
    "    A19 = tf.nn.leaky_relu(Z19, alpha=0.1)\n",
    "    Z20 = tf.nn.conv2d(A19, parameters['W20'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z20 = tf.nn.bias_add(Z20, parameters['B20'])\n",
    "    A20 = tf.nn.leaky_relu(Z20, alpha=0.1)\n",
    "    Z21 = tf.nn.conv2d(A20, parameters['W21'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z21 = tf.nn.bias_add(Z21, parameters['B21'])\n",
    "    A21 = tf.nn.leaky_relu(Z21, alpha=0.1)\n",
    "    Z22 = tf.nn.conv2d(A20, parameters['W22'], [1,2,2,1], padding=\"VALID\")\n",
    "    Z22 = tf.nn.bias_add(Z22, parameters['B22'])\n",
    "    A22 = tf.nn.leaky_relu(Z22, alpha=0.1)\n",
    "    \n",
    "    Z23 = tf.nn.conv2d(A22, parameters['W23'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z23 = tf.nn.bias_add(Z23, parameters['B23'])\n",
    "    A23 = tf.nn.leaky_relu(Z23, alpha=0.1)\n",
    "    Z24 = tf.nn.conv2d(A23, parameters['W24'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z24 = tf.nn.bias_add(Z24, parameters['B24'])\n",
    "    A24 = tf.nn.leaky_relu(Z24, alpha=0.1)\n",
    "    \n",
    "    A24 = tf.contrib.layers.flatten(A24)\n",
    "    FC1 = tf.contrib.layers.fully_connected(A24, 512, activation_fn=None)\n",
    "    FC2 = tf.contrib.layers.fully_connected(FC1, 4096, activation_fn=None)\n",
    "    FC3 = tf.contrib.layers.fully_connected(FC2, 1470, activation_fn=None)\n",
    "    \n",
    "    return FC3\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cost Function\n",
    "The cost function is slightly tricky in YOLOv1. The model is optimized end-to-end and has a composite loss function. The cost function has been coded for an output tensor of shape 7x7x(2x5 + 20)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_YOLOv1_cost(y_pred, y_ground):\n",
    "    '''\n",
    "    Calculates the loss for gradient descent\n",
    "    \n",
    "    y_pred - predicted values - a 7x7x(2x5 + 20) tensor\n",
    "    y_ground - ground truth labels - a 7x7x(2x5 + 20) tensor\n",
    "    '''\n",
    "    predictedBoxScores = np.reshape(y_pred, [-1, 7, 7, 30])\n",
    "    predictedClasses = predictedBoxScores[:, :, :, :20]\n",
    "    predictedObjectConfidence = predictedBoxScores[:, :, :, 20:22]\n",
    "    predictedBoxDimensions = predictedBoxScores[:, :, :, 22:]\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
