{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLOv1 Implementation\n",
    "This notebook aims to implement the YOLOv1 object detection algorithm and replicate the results as given in [this](https://arxiv.org/abs/1506.02640) paper.\n",
    "\n",
    "Steps involved:\n",
    "- pre-training weights on the ImageNet dataset.\n",
    "- Implement the YOLOv1 model\n",
    "\n",
    "## Step 1\n",
    "Pre-training weights in ImageNet dataset\n",
    "- prepare the modified network model\n",
    "- prepare the dataset for training - done in an accompanying notebook\n",
    "- Implement the diagnostic functions to track training\n",
    "- train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aditya/Documents/Projects/atgm_vision_module/env/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib as plt\n",
    "from yolo_utils import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_placeholders_pretrain(n_H, n_W, n_C, n_y):\n",
    "    '''\n",
    "    Function to create placeholder for the input tensors\n",
    "    \n",
    "    Args:\n",
    "    n_H = height of the image tensor\n",
    "    n_W = width of the image tensor\n",
    "    n_C = number of channels in the image tensor\n",
    "    n_y = number of classes/output features\n",
    "    \n",
    "    returns:\n",
    "    X, Y\n",
    "    '''\n",
    "    X = tf.placeholder(tf.float32, shape = (None, n_H, n_W, n_C))\n",
    "    Y = tf.placeholder(tf.float32, shape = (None, n_y))\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test script: DELETE\n",
    "c = [448, 448, 3, 10]\n",
    "X, Y = create_placeholders(*c)\n",
    "print(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code that initializes weight parameters based on the configuration given in an xml file\n",
    "path_to_xml = './YOLOv1_Pre_trained_Model.xml'\n",
    "pre_train_parameters = initialize_weights(path_to_xml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 - Prepare the modified network model for pre-trianing on ImagenNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation_pretrain(X, pre_train_parameters):\n",
    "    '''\n",
    "    Args:\n",
    "    X - placeholder for the initial feature tensor\n",
    "    pre_train_parameters - dictionary containing filters\n",
    "    \n",
    "    returns\n",
    "    FC1 - output of the last fully connected layer\n",
    "    \n",
    "    NOT IMPLEMENTED: NORMALIZATION\n",
    "    '''\n",
    "    # Conv\n",
    "    Z1 = tf.nn.conv2d(X, pre_train_parameters['W01'], [1,2,2,1], padding=\"SAME\")\n",
    "    Z1 = tf.nn.bias_add(Z1, pre_train_parameters['b01'])\n",
    "    A1 = tf.nn.leaky_relu(Z1, alpha=0.1)\n",
    "    \n",
    "    # Pool\n",
    "    P1 = tf.nn.max_pool(A1, [1,2,2,1], [1,2,2,1], padding=\"SAME\")\n",
    "    \n",
    "    # Conv\n",
    "    Z2 = tf.nn.conv2d(P1, pre_train_parameters['W02'], [1,1,1,1], padding=\"SAME\")\n",
    "    Z2 = tf.nn.bias_add(Z2, pre_train_parameters['b02'])\n",
    "    A2 = tf.nn.leaky_relu(Z2, alpha=0.1)\n",
    "    \n",
    "    # Pool\n",
    "    P2 = tf.nn.max_pool(A2, [1,2,2,1], [1,2,2,1], padding=\"SAME\")\n",
    "    \n",
    "    # Conv\n",
    "    Z3 = tf.nn.conv2d(P2, pre_train_parameters['W03'], [1,1,1,1], padding=\"SAME\")\n",
    "    Z3 = tf.nn.bias_add(Z3, pre_train_parameters['b03'])\n",
    "    A3 = tf.nn.leaky_relu(Z3, alpha=0.1)\n",
    "    Z4 = tf.nn.conv2d(A3, pre_train_parameters['W04'], [1,1,1,1], padding=\"SAME\")\n",
    "    Z4 = tf.nn.bias_add(Z4, pre_train_parameters['b04'])\n",
    "    A4 = tf.nn.leaky_relu(Z4, alpha=0.1)\n",
    "    Z5 = tf.nn.conv2d(A4, pre_train_parameters['W05'], [1,1,1,1], padding=\"SAME\")\n",
    "    Z5 = tf.nn.bias_add(Z5, pre_train_parameters['b05'])\n",
    "    A5 = tf.nn.leaky_relu(Z5, alpha=0.1)\n",
    "    Z6 = tf.nn.conv2d(A5, pre_train_parameters['W06'], [1,1,1,1], padding=\"SAME\")\n",
    "    Z6 = tf.nn.bias_add(Z6, pre_train_parameters['b06'])\n",
    "    A6 = tf.nn.leaky_relu(Z6, alpha=0.1)\n",
    "    \n",
    "    # Pool\n",
    "    P3 = tf.nn.max_pool(A6, [1,2,2,1], [1,2,2,1], padding=\"SAME\")\n",
    "    \n",
    "    # Conv\n",
    "    Z7 = tf.nn.conv2d(P3, pre_train_parameters['W07'], [1,1,1,1], padding=\"SAME\")\n",
    "    Z7 = tf.nn.bias_add(Z7, pre_train_parameters['b07'])\n",
    "    A7 = tf.nn.leaky_relu(Z7, alpha=0.1)\n",
    "    Z8 = tf.nn.conv2d(A7, pre_train_parameters['W08'], [1,1,1,1], padding=\"SAME\")\n",
    "    Z8 = tf.nn.bias_add(Z8, pre_train_parameters['b08'])\n",
    "    A8 = tf.nn.leaky_relu(Z8, alpha=0.1)\n",
    "    Z9 = tf.nn.conv2d(A8, pre_train_parameters['W09'], [1,1,1,1], padding=\"SAME\")\n",
    "    Z9 = tf.nn.bias_add(Z9, pre_train_parameters['b09'])\n",
    "    A9 = tf.nn.leaky_relu(Z9, alpha=0.1)\n",
    "    Z10 = tf.nn.conv2d(A9, pre_train_parameters['W10'], [1,1,1,1], padding=\"SAME\")\n",
    "    Z10 = tf.nn.bias_add(Z10, pre_train_parameters['b10'])\n",
    "    A10 = tf.nn.leaky_relu(Z10, alpha=0.1)\n",
    "    Z11 = tf.nn.conv2d(A10, pre_train_parameters['W11'], [1,1,1,1], padding=\"SAME\")\n",
    "    Z11 = tf.nn.bias_add(Z11, pre_train_parameters['b11'])\n",
    "    A11 = tf.nn.leaky_relu(Z11, alpha=0.1)\n",
    "    Z12 = tf.nn.conv2d(A11, pre_train_parameters['W12'], [1,1,1,1], padding=\"SAME\")\n",
    "    Z12 = tf.nn.bias_add(Z12, pre_train_parameters['b12'])\n",
    "    A12 = tf.nn.leaky_relu(Z12, alpha=0.1)\n",
    "    Z13 = tf.nn.conv2d(A12, pre_train_parameters['W13'], [1,1,1,1], padding=\"SAME\")\n",
    "    Z13 = tf.nn.bias_add(Z13, pre_train_parameters['b13'])\n",
    "    A13 = tf.nn.leaky_relu(Z13, alpha=0.1)\n",
    "    Z14 = tf.nn.conv2d(A13, pre_train_parameters['W14'], [1,1,1,1], padding=\"SAME\")\n",
    "    Z14 = tf.nn.bias_add(Z14, pre_train_parameters['b14'])\n",
    "    A14 = tf.nn.leaky_relu(Z14, alpha=0.1)\n",
    "    Z15 = tf.nn.conv2d(A14, pre_train_parameters['W15'], [1,1,1,1], padding=\"SAME\")\n",
    "    Z15 = tf.nn.bias_add(Z15, pre_train_parameters['b15'])\n",
    "    A15 = tf.nn.leaky_relu(Z15, alpha=0.1)\n",
    "    Z16 = tf.nn.conv2d(A15, pre_train_parameters['W16'], [1,1,1,1], padding=\"SAME\")\n",
    "    Z16 = tf.nn.bias_add(Z16, pre_train_parameters['b16'])\n",
    "    A16 = tf.nn.leaky_relu(Z16, alpha=0.1)\n",
    "    \n",
    "    # Pool\n",
    "    P4 = tf.nn.max_pool(A16, [1,2,2,1], [1,2,2,1], padding=\"SAME\")\n",
    "    \n",
    "    \n",
    "    # Conv\n",
    "    Z17 = tf.nn.conv2d(P4, pre_train_parameters['W17'], [1,1,1,1], padding=\"SAME\")\n",
    "    Z17 = tf.nn.bias_add(Z17, pre_train_parameters['b17'])\n",
    "    A17 = tf.nn.leaky_relu(Z17, alpha=0.1)\n",
    "    Z18 = tf.nn.conv2d(A17, pre_train_parameters['W18'], [1,1,1,1], padding=\"SAME\")\n",
    "    Z18 = tf.nn.bias_add(Z18, pre_train_parameters['b18'])\n",
    "    A18 = tf.nn.leaky_relu(Z18, alpha=0.1)\n",
    "    Z19 = tf.nn.conv2d(A18, pre_train_parameters['W19'], [1,1,1,1], padding=\"SAME\")\n",
    "    Z19 = tf.nn.bias_add(Z19, pre_train_parameters['b19'])\n",
    "    A19 = tf.nn.leaky_relu(Z19, alpha=0.1)\n",
    "    Z20 = tf.nn.conv2d(A19, pre_train_parameters['W20'], [1,1,1,1], padding=\"SAME\")\n",
    "    Z20 = tf.nn.bias_add(Z20, pre_train_parameters['b20'])\n",
    "    \n",
    "    # Pool\n",
    "    P5 = tf.nn.avg_pool(Z20, [1,2,2,1], [1,2,2,1], padding=\"SAME\")\n",
    "    \n",
    "    # flatten\n",
    "    P5 = tf.contrib.layers.flatten(P5)\n",
    "    \n",
    "    # Fully connected layer\n",
    "    FC1 = tf.contrib.layers.fully_connected(P5, 1000, activation_fn=None)\n",
    "    \n",
    "    return FC1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test script: DELETE\n",
    "tf.reset_default_graph()\n",
    "path_to_xml = './YOLOv1_Pre_trained_Model.xml'\n",
    "with tf.Session() as sess:\n",
    "    X, Y = create_placeholders_pretrain(448,448,3,1000)\n",
    "    pre_train_parameters = initialize_weights(path_to_xml)\n",
    "    FC1 = forward_propagation_pretrain(X, pre_train_parameters)\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    a = sess.run(FC1, {X: np.random.randn(2,448,448,3)})\n",
    "    print(\"Z20 = \" + str(a), \"Z20 shape = \" + str(a.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost_pretrain(FC1, Y):\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=FC1, labels=Y))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ImageNet dataset has been created in batches in an accompanying notbook. Each batch contains 2000 images and their corresponding labels. This is the main reason for the additional for loop in the ensuing cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_train_folder = './ImageNet_dataset/training_folder'\n",
    "h5_files_list = os.listdir(path_to_train_folder)\n",
    "print(h5_files_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below I implement the model function, which aggregates all the functions above, to train the model. I explicitly do not pass the train tensors as we are going to be reading them from another folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(xml_path, X_test=None, Y_test=None, learning_rate = 0.09, num_epochs = 100, \n",
    "          minibatch_size = 64, print_cost = True):\n",
    "    \n",
    "    # restting the default graph\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    # retrieve image shapes\n",
    "    #(m, n_Htr, n_Wtr, n_Ctr) = X_train.shape\n",
    "    #n_Y = Y_train.shape\n",
    "    \n",
    "    # global variables\n",
    "    costs = []\n",
    "    \n",
    "    # randomizer\n",
    "    seed = int(np.random.randint(1,100,1))\n",
    "    \n",
    "    # creating placeholders \n",
    "    X, Y = create_placeholders_pretrain(448,448,3,1000)\n",
    "    \n",
    "    # initializing parameters\n",
    "    pretrain_parameters = initialize_weights(xml_path)\n",
    "    \n",
    "    # forward prop\n",
    "    FC1 = forward_propagation_pretrain(X, pretrain_parameters)\n",
    "    \n",
    "    # compute cost\n",
    "    cost = compute_cost_pretrain(FC1, Y)\n",
    "    \n",
    "    # select the appropriate the optimizer\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "    \n",
    "    # initialize global variables\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    # train the session\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # run the initialization for the session\n",
    "        sess.run(init)\n",
    "        \n",
    "        # for loop for epoch/iterations\n",
    "        for epoch in range(num_epochs):\n",
    "            \n",
    "            # maintain the cost through an epoch\n",
    "            epoch_cost = 0\n",
    "            \n",
    "            # randomizer\n",
    "            seed += 1\n",
    "            \n",
    "            # path to training folder\n",
    "            PATH = './ImageNet_dataset/training_folder/'\n",
    "            \n",
    "            # set up the data\n",
    "            h5_files = os.listdir(PATH)\n",
    "            \n",
    "            # for loop to iterate through the h5 files\n",
    "            for file in h5_files:\n",
    "                \n",
    "                # DIAGNOSTIC print\n",
    "                print(\"setting up\" + file + \"for training\")\n",
    "                \n",
    "                # open the h5 file to form tensor\n",
    "                with h5py.File(PATH+file, mode = 'r') as h5_file:\n",
    "                    \n",
    "                    # extract features and labels\n",
    "                    X_train = np.asarray(h5_file['X_train'])\n",
    "                    Y_train = np.asarray(h5_file['Y_train'])\n",
    "                    \n",
    "                    # number of examples\n",
    "                    (m, n_Htr, n_Wtr, n_Ctr) = h5_file['X_train'].shape\n",
    "                    \n",
    "                    # ??? - REASON WHY\n",
    "                    num_minibatches = int(m/minibatch_size)\n",
    "\n",
    "                    # generate minibatches\n",
    "                    minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "\n",
    "                    # iterate through the minibatches\n",
    "                    for minibatch in minibatches:\n",
    "                        \n",
    "                        # procure minibatches\n",
    "                        (minibatch_X, minibatch_Y) = minibatch\n",
    "                        # optimize for cost, \n",
    "                        _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: tf.one_hot(minibatch_Y, 1000)})\n",
    "                        # cumulative minibatch cost\n",
    "                        epoch_cost += minibatch_cost/num_minibatches\n",
    "            \n",
    "            # Print the cost after every 5 epochs\n",
    "            if print_cost == True and epoch % 1 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "                costs.append(epoch_cost)\n",
    "                \n",
    "    return pretrain_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 7, 3, 64]\n",
      "[3, 3, 64, 192]\n",
      "[1, 1, 192, 128]\n",
      "[3, 3, 128, 256]\n",
      "[1, 1, 256, 256]\n",
      "[3, 3, 256, 512]\n",
      "[1, 1, 512, 256]\n",
      "[3, 3, 256, 512]\n",
      "[1, 1, 512, 256]\n",
      "[3, 3, 256, 512]\n",
      "[1, 1, 512, 256]\n",
      "[3, 3, 256, 512]\n",
      "[1, 1, 512, 256]\n",
      "[3, 3, 256, 512]\n",
      "[1, 1, 512, 512]\n",
      "[3, 3, 512, 1024]\n",
      "[1, 1, 1024, 512]\n",
      "[3, 3, 512, 1024]\n",
      "[1, 1, 1024, 512]\n",
      "[3, 3, 512, 1024]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape must be rank 1 but is rank 2 for 'BiasAdd' (op: 'BiasAdd') with input shapes: [?,224,224,64], [64,1].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/Documents/Projects/atgm_vision_module/env/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    685\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[1;32m    687\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Projects/atgm_vision_module/env/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Shape must be rank 1 but is rank 2 for 'BiasAdd' (op: 'BiasAdd') with input shapes: [?,224,224,64], [64,1].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-59af827266c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'YOLOv1_Pre_trained_Model.xml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-74553fb50e99>\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(xml_path, X_test, Y_test, learning_rate, num_epochs, minibatch_size, print_cost)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# forward prop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mFC1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_propagation_pretrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrain_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# compute cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-db4623e66589>\u001b[0m in \u001b[0;36mforward_propagation_pretrain\u001b[0;34m(X, pre_train_parameters)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Conv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mZ1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_train_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W01'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"SAME\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mZ1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_train_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b01'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mA1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Projects/atgm_vision_module/env/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mbias_add\u001b[0;34m(value, bias, data_format, name)\u001b[0m\n\u001b[1;32m   1453\u001b[0m     \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1454\u001b[0m     \u001b[0mbias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"bias\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1455\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_nn_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bias_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Projects/atgm_vision_module/env/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36m_bias_add\u001b[0;34m(value, bias, data_format, name)\u001b[0m\n\u001b[1;32m    452\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_graph_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m--> 454\u001b[0;31m         \"BiasAdd\", value=value, bias=bias, data_format=data_format, name=name)\n\u001b[0m\u001b[1;32m    455\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Projects/atgm_vision_module/env/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Projects/atgm_vision_module/env/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2956\u001b[0m         op_def=op_def)\n\u001b[1;32m   2957\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2958\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2959\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2960\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Projects/atgm_vision_module/env/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   2207\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2209\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2210\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2211\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m~/Documents/Projects/atgm_vision_module/env/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   2157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2158\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2159\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2161\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Projects/atgm_vision_module/env/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, require_shape_fn)\u001b[0m\n\u001b[1;32m    625\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    626\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m                                   require_shape_fn)\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Projects/atgm_vision_module/env/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    689\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape must be rank 1 but is rank 2 for 'BiasAdd' (op: 'BiasAdd') with input shapes: [?,224,224,64], [64,1]."
     ]
    }
   ],
   "source": [
    "_, _, parameters = model('YOLOv1_Pre_trained_Model.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2\n",
    "Implement the YOLOv1 model\n",
    "\n",
    "- Implement Forward Propagation function\n",
    "- Implement cost function\n",
    "- Implement model function\n",
    "\n",
    "Create placeholders for the feature and label tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test script for the create-placeholder function\n",
    "X, Y = create_placeholders(448, 448, 3, 1000)\n",
    "print (\"X = \" + str(X))\n",
    "print (\"Y = \" + str(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare and initialize the parameters that are used in the model. Traditional implementation of a CNN would have had to initialize them randomly. But the YOLOv1 model is pre-trained on ImageNet. These weights can be procured from Step 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "    \"\"\"\n",
    "    Yet to be coded\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the YOLOv1 CNN forward propogation function. Facts that you need to paid attention\n",
    "- Linear activation for the final layer, leaky relu for the rest with alpha = 0.1\n",
    "- Any image is resized to 448x448. This is the standard input.\n",
    "- Implement a function to load filter dimensions from an xml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# experimenting with the ElementTree API\n",
    "tf.reset_default_graph()\n",
    "parameters = {}\n",
    "tree = ET.parse('Configuration.xml')\n",
    "root = tree.getroot()\n",
    "for child in root:\n",
    "    size = []\n",
    "    for child1 in child:\n",
    "        # print(child.attrib['name'], child1.tag, child1.text)\n",
    "        if (child1.tag == 'dimension'):\n",
    "            size.append((int)(child1.text))\n",
    "            size.append((int)(child1.text))\n",
    "        if (child1.tag == 'input'):\n",
    "            size.append((int)(child1.text))\n",
    "        if (child1.tag == 'output'):\n",
    "            size.append((int)(child1.text))\n",
    "    print(size)\n",
    "    W = tf.get_variable(child.attrib['name'], size, initializer = tf.contrib.layers.xavier_initializer(seed = 0)) \n",
    "    parameters[child.attrib['name']] = W\n",
    "    B = tf.Variable(tf.constant(0.01, shape=[size[-1]]))\n",
    "    parameters['B'+(child.attrib['name'][1:])] = B\n",
    "print(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in parameters:\n",
    "    print(key, parameters[key])\n",
    "    print(parameters[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_initialize_weights(xml_file):\n",
    "    '''\n",
    "    Reads model parameter weights from xml_file and initializes filters and biases\n",
    "    \n",
    "    Args:\n",
    "    xml_file - configuration xml with absolute path\n",
    "    \n",
    "    Returns:\n",
    "    parameters - a dictionary containing initialized parameters\n",
    "    '''\n",
    "    parameters = {}\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    for child in root:\n",
    "        size = []\n",
    "        for child1 in child:\n",
    "            # print(child.attrib['name'], child1.tag, child1.text)\n",
    "            if (child1.tag == 'dimension'):\n",
    "                size.append((int)(child1.text))\n",
    "                size.append((int)(child1.text))\n",
    "            if (child1.tag == 'input'):\n",
    "                size.append((int)(child1.text))\n",
    "            if (child1.tag == 'output'):\n",
    "                size.append((int)(child1.text))\n",
    "        print(size)\n",
    "        W = tf.get_variable(child.attrib['name'], size, initializer = tf.contrib.layers.xavier_initializer(seed = 0)) \n",
    "        parameters[child.attrib['name']] = W\n",
    "        B = tf.Variable(tf.constant(0.01, shape=[size[-1]]))\n",
    "        parameters['B'+(child.attrib['name'][1:])] = B\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward Propogation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation_YOLOv1(X, parameters):\n",
    "    '''\n",
    "    Args:\n",
    "    X - placeholder for the initial feature tensor\n",
    "    parameters - dictionary containing filters\n",
    "    \n",
    "    returns\n",
    "    Z8 - output of the last LINEAR layer\n",
    "    \n",
    "    NOT IMPLEMENTED: NORMALIZATION\n",
    "    '''\n",
    "    \n",
    "    Z1 = tf.nn.conv2d(X, parameters['W01'], [1,2,2,1], padding=\"VALID\")\n",
    "    Z1 = tf.nn.bias_add(Z1, parameters['B01'])\n",
    "    A1 = tf.nn.leaky_relu(Z1, alpha=0.1)\n",
    "    P1 = tf.nn.max_pool(A1, [1,2,2,1], [1,2,2,1], padding=\"VALID\")\n",
    "    \n",
    "    \n",
    "    Z2 = tf.nn.conv2d(P1, parameters['W02'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z2 = tf.nn.bias_add(Z2, parameters['B02'])\n",
    "    A2 = tf.nn.leaky_relu(Z2, alpha=0.1)\n",
    "    P2 = tf.nn.max_pool(A2, [1,2,2,1], [1,2,2,1], padding=\"VALID\")\n",
    "    \n",
    "    Z3 = tf.nn.conv2d(P2, parameters['W03'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z3 = tf.nn.bias_add(Z3, parameters['B03'])\n",
    "    A3 = tf.nn.leaky_relu(Z3, alpha=0.1)\n",
    "    Z4 = tf.nn.conv2d(A3, parameters['W04'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z4 = tf.nn.bias_add(Z4, parameters['B04'])\n",
    "    A4 = tf.nn.leaky_relu(Z4, alpha=0.1)\n",
    "    Z5 = tf.nn.conv2d(A4, parameters['W05'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z5 = tf.nn.bias_add(Z5, parameters['B05'])\n",
    "    A5 = tf.nn.leaky_relu(Z5, alpha=0.1)\n",
    "    Z6 = tf.nn.conv2d(A5, parameters['W06'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z6 = tf.nn.bias_add(Z6, parameters['B06'])\n",
    "    A6 = tf.nn.leaky_relu(Z6, alpha=0.1)\n",
    "    P3 = tf.nn.max_pool(A6, [1,2,2,1], [1,2,2,1], padding=\"VALID\")\n",
    "    \n",
    "    Z7 = tf.nn.conv2d(P3, parameters['W07'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z7 = tf.nn.bias_add(Z7, parameters['B07'])\n",
    "    A7 = tf.nn.leaky_relu(Z7, alpha=0.1)\n",
    "    Z8 = tf.nn.conv2d(A7, parameters['W08'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z8 = tf.nn.bias_add(Z8, parameters['B08'])\n",
    "    A8 = tf.nn.leaky_relu(Z8, alpha=0.1)\n",
    "    Z9 = tf.nn.conv2d(A8, parameters['W09'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z9 = tf.nn.bias_add(Z9, parameters['B09'])\n",
    "    A9 = tf.nn.leaky_relu(Z9, alpha=0.1)\n",
    "    Z10 = tf.nn.conv2d(A9, parameters['W10'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z10 = tf.nn.bias_add(Z10, parameters['B10'])\n",
    "    A10 = tf.nn.leaky_relu(Z10, alpha=0.1)\n",
    "    Z11 = tf.nn.conv2d(P10, parameters['W11'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z11 = tf.nn.bias_add(Z11, parameters['B11'])\n",
    "    A11 = tf.nn.leaky_relu(Z11, alpha=0.1)\n",
    "    Z12 = tf.nn.conv2d(A11, parameters['W12'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z12 = tf.nn.bias_add(Z12, parameters['B12'])\n",
    "    A12 = tf.nn.leaky_relu(Z12, alpha=0.1)\n",
    "    Z13 = tf.nn.conv2d(A12, parameters['W13'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z13 = tf.nn.bias_add(Z13, parameters['B13'])\n",
    "    A13 = tf.nn.leaky_relu(Z13, alpha=0.1)\n",
    "    Z14 = tf.nn.conv2d(A13, parameters['W14'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z14 = tf.nn.bias_add(Z14, parameters['B14'])\n",
    "    A14 = tf.nn.leaky_relu(Z14, alpha=0.1)\n",
    "    Z15 = tf.nn.conv2d(P4, parameters['W15'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z15 = tf.nn.bias_add(Z15, parameters['B15'])\n",
    "    A15 = tf.nn.leaky_relu(Z15, alpha=0.1)\n",
    "    Z16 = tf.nn.conv2d(A15, parameters['W16'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z16 = tf.nn.bias_add(Z16, parameters['B16'])\n",
    "    A16 = tf.nn.leaky_relu(Z16, alpha=0.1)\n",
    "    P4 = tf.nn.max_pool(A16, [1,2,2,1], [1,2,2,1], padding=\"VALID\")\n",
    "    \n",
    "    \n",
    "    Z17 = tf.nn.conv2d(P4, parameters['W17'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z17 = tf.nn.bias_add(Z17, parameters['B17'])\n",
    "    A17 = tf.nn.leaky_relu(Z17, alpha=0.1)\n",
    "    Z18 = tf.nn.conv2d(A17, parameters['W18'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z18 = tf.nn.bias_add(Z18, parameters['B18'])\n",
    "    A18 = tf.nn.leaky_relu(Z18, alpha=0.1)\n",
    "    Z19 = tf.nn.conv2d(A18, parameters['W19'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z19 = tf.nn.bias_add(Z19, parameters['B19'])\n",
    "    A19 = tf.nn.leaky_relu(Z19, alpha=0.1)\n",
    "    Z20 = tf.nn.conv2d(A19, parameters['W20'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z20 = tf.nn.bias_add(Z20, parameters['B20'])\n",
    "    A20 = tf.nn.leaky_relu(Z20, alpha=0.1)\n",
    "    Z21 = tf.nn.conv2d(A20, parameters['W21'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z21 = tf.nn.bias_add(Z21, parameters['B21'])\n",
    "    A21 = tf.nn.leaky_relu(Z21, alpha=0.1)\n",
    "    Z22 = tf.nn.conv2d(A20, parameters['W22'], [1,2,2,1], padding=\"VALID\")\n",
    "    Z22 = tf.nn.bias_add(Z22, parameters['B22'])\n",
    "    A22 = tf.nn.leaky_relu(Z22, alpha=0.1)\n",
    "    \n",
    "    Z23 = tf.nn.conv2d(A22, parameters['W23'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z23 = tf.nn.bias_add(Z23, parameters['B23'])\n",
    "    A23 = tf.nn.leaky_relu(Z23, alpha=0.1)\n",
    "    Z24 = tf.nn.conv2d(A23, parameters['W24'], [1,1,1,1], padding=\"VALID\")\n",
    "    Z24 = tf.nn.bias_add(Z24, parameters['B24'])\n",
    "    A24 = tf.nn.leaky_relu(Z24, alpha=0.1)\n",
    "    \n",
    "    A24 = tf.contrib.layers.flatten(A24)\n",
    "    FC1 = tf.contrib.layers.fully_connected(A24, 512, activation_fn=None)\n",
    "    FC2 = tf.contrib.layers.fully_connected(FC1, 4096, activation_fn=None)\n",
    "    FC3 = tf.contrib.layers.fully_connected(FC2, 1470, activation_fn=None)\n",
    "    \n",
    "    return FC3\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cost Function\n",
    "The cost function is slightly tricky in YOLOv1. The model is optimized end-to-end and has a composite loss function. The cost function has been coded for an output tensor of shape 7x7x(2x5 + 20)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_YOLOv1_cost(y_pred, y_ground):\n",
    "    '''\n",
    "    Calculates the loss for gradient descent\n",
    "    \n",
    "    y_pred - predicted values - a 7x7x(2x5 + 20) tensor\n",
    "    y_ground - ground truth labels - a 7x7x(2x5 + 20) tensor\n",
    "    '''\n",
    "    predictedBoxScores = np.reshape(y_pred, [-1, 7, 7, 30])\n",
    "    predictedClasses = predictedBoxScores[:, :, :, :20]\n",
    "    predictedObjectConfidence = predictedBoxScores[:, :, :, 20:22]\n",
    "    predictedBoxDimensions = predictedBoxScores[:, :, :, 22:]\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
